{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1991ca70-618f-4867-a2b0-f466c209646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/big/venv/cuda/bin/python\n",
    "from langchain_gigachat.chat_models import GigaChat\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import uuid\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import configparser\n",
    "from time import sleep\n",
    "from glob import glob\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b57b047-317d-4655-aa57-befee2d2060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid=uuid.uuid1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e42a2ca-5841-4e7e-8155-5c975a1604ea",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7801b666-b39a-4796-9860-72ea7c3f379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# читаем конфиг\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "API_KEY=config.get('gigachat', 'authkey')\n",
    "\n",
    "# модель\n",
    "model = GigaChat(\n",
    "    credentials=API_KEY,\n",
    "    verify_ssl_certs=False,\n",
    ")\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=800,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83523a36-3053-44d9-aefb-947cefbb61b2",
   "metadata": {},
   "source": [
    "## Работа с голосом (текст <=> голос)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "092c6de8-cc4d-4356-893a-9107ac1adbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(text, out_filename='output.mp3', play = False):\n",
    "    tts = gTTS(text=text, lang='ru')\n",
    "    tts.save(out_filename)\n",
    "    if play:\n",
    "        os.system(f'mpg321 {out_filename}')  # Воспроизведение файла с использованием mpg\n",
    "\n",
    "def file_to_text(filename='in.wav'):\n",
    "    r = sr.Recognizer()\n",
    "    audio = sr.AudioData.from_file(filename)\n",
    "    said = \"\"\n",
    "    try:\n",
    "        said = r.recognize_google(audio, language = 'ru-RU')\n",
    "    except Exception as e:\n",
    "        print(\"Exception: + \" + str(e))\n",
    "    return said\n",
    "\n",
    "def record_mic_file(filename='in.wav'):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        \n",
    "        print('Говорите')\n",
    "        audio = r.listen(source)\n",
    "        \n",
    "    # write audio to a WAV file\n",
    "    with open(filename, \"wb\") as f:\n",
    "            f.write(audio.get_wav_data())        \n",
    "\n",
    "def listen_speech():\n",
    "    record_mic_file()\n",
    "    return file_to_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5746b2-53ad-4e8d-8795-c539530f78d1",
   "metadata": {},
   "source": [
    "## Читаем вакансию и генерируем списки вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5123d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy = open('../frontend/vacancy/vak1.txt').read()\n",
    "resume = open('../frontend/resume/Александр Иванович Павлов - специалист ИТ.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c2c3190-36c1-4091-8b47-4b2bec69ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_base_question_list(resume):\n",
    "    bq = open('base_questions.txt').read()\n",
    "    \n",
    "    promt=f'''\n",
    "    резюме: {resume}\n",
    "    '''\n",
    "    \n",
    "    bq=f'''Сформулиуй краткий список вопросов кандидату по: \n",
    "    {bq}\n",
    "    Ответ не должен включать пояснения и дополнительную информацию\n",
    "    '''\n",
    "    res = model.invoke([SystemMessage(promt), HumanMessage(bq)])\n",
    "    questions = res.content.replace('- ','').split('\\n')\n",
    "    return questions\n",
    "\n",
    "def generate_redflag_question_list():\n",
    "    bq = open('redflags.txt').read()\n",
    "    promt=f'''\n",
    "    резюме: {resume}\n",
    "    '''\n",
    "    bq=f'''Сформулиуй краткий список вопросов кандидату по: \n",
    "    {bq}\n",
    "    Список вопросов не должен включать пояснения и дополнительную информацию. \n",
    "    Каждый вопрос должен быть в отдельной строке.\n",
    "    '''\n",
    "    res = model.invoke([SystemMessage(promt), HumanMessage(bq)])\n",
    "    questions = res.content.replace('- ','').split('\\n')\n",
    "    return questions\n",
    "\n",
    "def filter_redflag_question_list(questions, resume):\n",
    "    promt=f'''\n",
    "    резюме: {resume}\n",
    "    '''\n",
    "    res = model.invoke([SystemMessage(promt), HumanMessage('Напиши кратко пол кандидата мужчина или женщина?')])\n",
    "    promt=f'''\n",
    "    список вопросов: {questions}\n",
    "    '''\n",
    "    bq=f'''Убери из списка  вопросы освещенные в резюме. \n",
    "    Вопросы о беременности и детях надо задавать только кандидату-женщине. Учитывай что кандидат не {res.content}.\n",
    "    Каждый вопрос должен быть в отдельной строке.\n",
    "    Список вопросов не должен включать пояснения и дополнительную информацию.\n",
    "    '''\n",
    "    res = model.invoke([SystemMessage(promt), HumanMessage(bq)])\n",
    "    questions = res.content.replace('- ','').split('\\n')\n",
    "    return questions\n",
    "    \n",
    "    \n",
    "\n",
    "def generate_skills_question_list(vacancy):\n",
    "    promt=f'''\n",
    "    вакансия: {vacancy}\n",
    "    '''\n",
    "    bq=f'''Сформулиуй краткий список вопросов по списку требований кандидату согласно вакансии\n",
    "    \n",
    "    Список вопросов не должен включать пояснения и дополнительную информацию. \n",
    "    '''\n",
    "    res = model.invoke([SystemMessage(promt), HumanMessage(bq)])\n",
    "    questions = res.content.replace('- ','').split('\\n')\n",
    "    return questions\n",
    "\n",
    "def filter_skills_question_list(question_list, resume):\n",
    "    promt=f'''\n",
    "    резюме: {resume}\n",
    "\n",
    "    список вопросов: {question_list}\n",
    "    '''\n",
    "    bq=f'''Убери вопросы освещенные в резюме. Список вопросов не должен включать пояснения и дополнительную информацию. \n",
    "    '''\n",
    "    res = model.invoke([SystemMessage(promt), HumanMessage(bq)])\n",
    "    questions = res.content.replace('- ','').split('\\n')\n",
    "    return questions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8871b863-28be-47bd-a5a8-df359d4256b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_question_list = generate_base_question_list(resume)\n",
    "redflag_question_list = generate_redflag_question_list()\n",
    "skill_question_list = generate_skills_question_list(vacancy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a60ee7-d4f7-4f97-9a68-1736f5c4fb21",
   "metadata": {},
   "source": [
    "## Фильтруем  список вопросов под конкретного кандидата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c7dc1b3-1f53-4cbf-a13b-dc5f9178c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "redflag_question_list = filter_redflag_question_list('\\n'.join(redflag_question_list),resume)\n",
    "\n",
    "skill_question_list = filter_skills_question_list('\\n'.join(skill_question_list), resume)\n",
    "\n",
    "\n",
    "base_question_list=[re.sub('\\<\\S+\\>','',s) for s in base_question_list]\n",
    "redflag_question_list=[re.sub('\\<\\S+\\>','',s) for s in redflag_question_list]\n",
    "skill_question_list=[re.sub('\\<\\S+\\>','',s) for s in skill_question_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "efbba643-67bd-480e-877f-4765f755fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_idx = 0\n",
    "redflag_idx = 0\n",
    "skill_idx=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "280f443f-5143-455f-a89b-11117cbee981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Был ли у вас опыт судимостей?',\n",
       " 'Употребляли ли вы когда-либо наркотики или имели проблемы с алкоголем?']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redflag_question_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ccc2b7-b642-4869-b082-e4b272a379a4",
   "metadata": {},
   "source": [
    "## Настройка workflow графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5a61e3f-3b39-4fa6-aaa7-a2b5a337b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "import datetime\n",
    "import psycopg2\n",
    "import sqlalchemy as sa\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87961467-6372-4080-8703-15a50dff8540",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82c13b5-cfaf-4852-932f-9b2418632974",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Postgres interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "251e98dc-0750-4f2b-afa5-9b60eab24283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_tables():\n",
    "    con = psycopg2.connect(database='hrdb',user='hruser',password='hrpassword', host='localhost')\n",
    "    cur=con.cursor()\n",
    "\n",
    "    cur.execute('''\n",
    "    create table if not exists interviews\n",
    "    (\n",
    "    uuid varchar(100) not null,\n",
    "    message text not null,\n",
    "    date timestamp default now(),\n",
    "    vacancy varchar(100) not null,\n",
    "    resume varchar(100) not null,\n",
    "    state varchar(100) default 'created'\n",
    "    )    ''')\n",
    "    \n",
    "    cur.execute('''\n",
    "    create table if not exists vacancies (\n",
    "    vacancy_file varchar(100) not null unique,\n",
    "    vacancy_text text not null,\n",
    "    requirements varchar(300)[]\n",
    "    ); ''')\n",
    "\n",
    "    cur.execute('''\n",
    "    create table if not exists resume (\n",
    "    resume_file varchar(100) not null unique,\n",
    "    resume_text text not null,\n",
    "    fio varchar(100),\n",
    "    skills varchar(100)[]\n",
    "    );\n",
    "\n",
    "    ''')\n",
    "\n",
    "    \n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "\n",
    "init_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eedc7a-1103-4ee5-9300-4fde591101fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "\n",
    "### User\n",
    "def input_from_user():\n",
    "    txt = input()\n",
    "    return txt\n",
    "    \n",
    "def send_to_user(txt):\n",
    "    print('AI: ', txt)\n",
    "    \n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: State):\n",
    "    print('call_model:',state)\n",
    "    trimmed_messages=trimmer.invoke(state['messages'], config=config)\n",
    "    response = model.invoke(trimmed_messages,config=config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# Define the function that calls the model\n",
    "def plan_interview(state: State):\n",
    "    #print('plan_interview:',state)\n",
    "    msgs=[]\n",
    "    msg=AIMessage(\"Когда бы Вам было удобно запланировать интервью?\")\n",
    "    msgs.append(msg)\n",
    "    send_to_user(msg.content)\n",
    "    answer = input_from_user()\n",
    "    curdate = datetime.date.today().strftime('%d.%m.%Y')\n",
    "    res= model.invoke([SystemMessage(f'напиши дату планируемого интервью в формате dd.mm.YYYY. Текущая дата {curdate}'),HumanMessage(answer)])\n",
    "    send_to_user(f'Планируемая дата: {res.content}')\n",
    "    msgs.append(res.content)\n",
    "    return {'messages':msgs}\n",
    "\n",
    "\n",
    "def ask_base(state: State):\n",
    "    print('ask_base')\n",
    "    global base_idx\n",
    "    if len(base_question_list) <= base_idx:\n",
    "        send_to_user('Переходим к следующему блоку вопросов.')\n",
    "        return {'messages':[]}\n",
    "    q = base_question_list[base_idx]\n",
    "    send_to_user(q)\n",
    "    base_idx=base_idx+1\n",
    "    answer = input_from_user()\n",
    "    return {'messages':[AIMessage(q),HumanMessage(answer)]}\n",
    "\n",
    "def ask_redflags(state: State):\n",
    "    print('ask_redflag')\n",
    "    global redflag_idx\n",
    "    if len(redflag_question_list) <= redflag_idx:\n",
    "        send_to_user('Переходим к следующему блоку вопросов.')\n",
    "        return {'messages':[]}\n",
    "    q = redflag_question_list[redflag_idx]\n",
    "    send_to_user(q)\n",
    "    redflag_idx=redflag_idx+1\n",
    "    answer = input_from_user()\n",
    "    return {'messages':[AIMessage(q),HumanMessage(answer)]}\n",
    "\n",
    "def ask_skills(state: State):\n",
    "    print('ask_skills')\n",
    "    global skill_idx\n",
    "    if len(skill_question_list) <= skill_idx:\n",
    "        send_to_user('Переходим к следующему блоку вопросов.')\n",
    "        return {'messages':[]}\n",
    "    q = skill_question_list[skill_idx]\n",
    "    send_to_user(q)\n",
    "    skill_idx=skill_idx+1\n",
    "    answer = input_from_user()\n",
    "    return {'messages':[AIMessage(q),HumanMessage(answer)]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ask_base_details(state: State):\n",
    "    print('ask_base_details')\n",
    "    r = model.invoke(state['messages']+[\n",
    "        HumanMessage('Сформулируй уточняющий вопрос так чтобы ответ на предыдущий вопрос стал полным')],config=config)\n",
    "    send_to_user(r.content)\n",
    "    answer = input_from_user()\n",
    "    return {'messages':[r.content,HumanMessage(answer)]}\n",
    "\n",
    "    \n",
    "def greeting(state: State):\n",
    "    print('greeting')\n",
    "    response = model.invoke([\n",
    "        SystemMessage(f'резюме: {resume}'), \n",
    "        HumanMessage('Поздоровайся. Скажи что ты помощник с искусственным интелектом. Ты будешь проводить предварительное собеседование. Скажи Здравствуйте и имя отчество кандидата.')\n",
    "    ],config=config)\n",
    "    send_to_user(response.content)\n",
    "    return {'messages':[SystemMessage(f'резюме: {resume}'), \n",
    "response,]}\n",
    "\n",
    "def goodbye(state: State):\n",
    "    send_to_user('Всего доброго. Мы с Вами свяжемся')\n",
    "    return {'messages':[]}\n",
    "    \n",
    "def ready_for_interview(state: State):\n",
    "    print('ready_to_interview')\n",
    "    response = model.invoke([\n",
    "        SystemMessage(f'резюме: {resume}'), \n",
    "        HumanMessage('Спроси готов ли кандидат пройти собеседование сейчас')\n",
    "    ],config=config)\n",
    "    send_to_user(response.content)\n",
    "    answer = input_from_user()\n",
    "    return {'messages':[response,HumanMessage(answer)]}\n",
    "\n",
    "#answer = input_from_user()\n",
    "    #return {'messages':[response, HumanMessage(answer)]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8bdaf3-ac2c-4ca1-897f-302b73838f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ready_to_interview(state: State):\n",
    "    print('check_ready_to_interview', state['messages'][-1].content)\n",
    "    response = model.invoke([\n",
    "        SystemMessage('Ответ положительный. Напиши да или нет.'), \n",
    "        state['messages'][-1]], config=config)\n",
    "    if 'нет'  in response.content.lower():\n",
    "        print('not ready')\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7500881-63f4-46d8-bc99-9109bbac21ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_promt = '''\n",
    "Проанализируй ответ на вопрос. Ответ общий и уклончивый и требует уточнений или ответ законченный и конкретный.\n",
    "Напиши без дополнительных объястнений одно из двух: \"Да, требует уточнений\" или \"Нет, ответ законченный\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7ca64-dbf1-4cea-bb79-b318efd138cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_base_answer(state: State):\n",
    "    print('check_base_answer')\n",
    "    answers[base_question_list[base_idx-1]]+='\\n'+state['messages'][-1].content\n",
    "    \n",
    "    if base_idx >= len(base_question_list):\n",
    "        return 'next_section'\n",
    "    r = model.invoke(state['messages']+[HumanMessage(analyze_promt),])\n",
    "    print('Анализ ответа:', r.content)\n",
    "    if 'ответ законченный' in r.content.lower():\n",
    "        return 'next_question'\n",
    "    else:\n",
    "        return 'details'\n",
    "\n",
    "def check_redflag_answer(state: State):\n",
    "    print('check_redflag_answer')\n",
    "    answers[base_question_list[base_idx-1]]+='\\n'+state['messages'][-1].content\n",
    "    if redflag_idx >= len(redflag_question_list):\n",
    "        return 'next_section'\n",
    "\n",
    "    r = model.invoke(state['messages']+[HumanMessage(analyze_promt),])\n",
    "    print('Анализ ответа:', r.content)\n",
    "    if 'требует уточнений' in r.content.lower():\n",
    "        return 'details'\n",
    "    else:\n",
    "        return 'next_question'\n",
    "    \n",
    "\n",
    "def check_skills_answer(state: State):\n",
    "    if skill_idx >= len(skill_question_list):\n",
    "        return 'next_section'\n",
    "    r = model.invoke(state['messages']+[HumanMessage(analyze_promt),])\n",
    "    print('Анализ ответа:', r.content)\n",
    "    if 'требует уточнений' in r.content.lower():\n",
    "        return 'details'\n",
    "    else:\n",
    "        return 'next_question'\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adeffa6-cb85-4b25-ae30-d78601ccae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"greeting\")\n",
    "workflow.add_edge('greeting', 'ready_for_interview')\n",
    "workflow.add_conditional_edges('ready_for_interview', check_ready_to_interview, { True: 'ask_base', False: 'plan_interview'})\n",
    "workflow.add_edge('plan_interview', 'goodbye')\n",
    "\n",
    "workflow.add_conditional_edges('ask_base', check_base_answer, \n",
    "                               { \n",
    "                                   'details': 'ask_addition_base', \n",
    "                                   'next_question': 'ask_base', \n",
    "                                   'next_section':'ask_redflags'\n",
    "                               })\n",
    "workflow.add_conditional_edges('ask_redflags', check_redflag_answer, \n",
    "                               { \n",
    "                                   'details': 'ask_addition_redflags', \n",
    "                                   'next_question': 'ask_redflags', \n",
    "                                   'next_section':'ask_skills'\n",
    "                               })\n",
    "workflow.add_conditional_edges('ask_skills', check_skills_answer, \n",
    "                               { \n",
    "                                   'details': 'ask_addition_skills', \n",
    "                                   'next_question': 'ask_skills', \n",
    "                                   'next_section':'goodbye'\n",
    "                               })\n",
    "workflow.add_edge('goodbye', END)\n",
    "\n",
    "workflow.add_edge('ask_addition_base', 'ask_base')\n",
    "workflow.add_edge('ask_addition_redflags', 'ask_redflags')\n",
    "workflow.add_edge('ask_addition_skills', 'ask_skills')\n",
    "\n",
    "\n",
    "workflow.add_node(\"greeting\", greeting)\n",
    "workflow.add_node(\"ready_for_interview\", ready_for_interview)\n",
    "workflow.add_node(\"plan_interview\", plan_interview)\n",
    "workflow.add_node(\"ask_base\", ask_base)\n",
    "workflow.add_node(\"ask_addition_base\", ask_base_details)\n",
    "workflow.add_node(\"ask_addition_redflags\", ask_base_details)\n",
    "workflow.add_node(\"ask_addition_skills\", ask_base_details)\n",
    "workflow.add_node(\"ask_redflags\", ask_redflags)\n",
    "workflow.add_node(\"ask_skills\", ask_skills)\n",
    "workflow.add_node(\"goodbye\", goodbye)\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd44f23-3475-48c4-8153-02241426170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_idx = 0\n",
    "redflag_idx = 0\n",
    "skill_idx=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9baef64-056c-45ae-8ff2-f1ea492ea56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input = ''):\n",
    "    for event in app.stream({\"messages\": []}, config=config):\n",
    "        pass\n",
    "\n",
    "stream_graph_updates(user_input)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6ae7c-8f35-48b3-940f-11cf2c41acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke([HumanMessage('Привет')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19c160-485d-4e29-a93d-9dc1ae1bcc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eceb3f-208f-4fe1-be50-1872be78c18a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ccdc4-265d-42a5-a4ee-8180b30b1c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask():\n",
    "    txt = 'привет, как тебя зовут?'#input()\n",
    "    print(txt)\n",
    "    input_messages = [SystemMessage('Дай ответ на английском языке'),HumanMessage(txt)]\n",
    "    output = model.invoke(input_messages, config)\n",
    "    print(output)\n",
    "    output[\"messages\"][-1].pretty_print()\n",
    "    text_to_speech(output[\"messages\"][-1].content)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268aa17d-99f6-48a8-b5f5-376dd78dfc5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65ecb1-fd98-4e86-989d-77f04170eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_human(query):\n",
    "    text_to_speech(query,play=True)\n",
    "    txt = input()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3462aa7-d44a-49bf-91fd-24cb1e782ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    'поздоровайся, узнай как зовут собеседника',\n",
    "    'узнай дату рождения',\n",
    "    'предложи пройти собеседование сейчас',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae393dbe-5325-4517-abde-78802dfb71a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1765b-3b93-42bc-9dca-84d05e25b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_connection():\n",
    "    txt=ask_human('Здравствуйте, проверка связи. Скажите что-нибудь')\n",
    "    if txt=='':\n",
    "        text_to_speech('')\n",
    "        print('!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14311df-4008-41ab-af14-ccfc1e723052",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in questions:\n",
    "    \n",
    "    txt=ask_human(q)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966be219-6dba-4c15-8645-e26cf92a7d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bddded4-2556-4750-89eb-5e37401e5585",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398fc86-41cc-4bbb-b618-ed26cf0319ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d20c6-4536-4a56-ade9-a6b55c2fbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "j[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ee802-eb8d-4244-9e91-a701055b4134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
